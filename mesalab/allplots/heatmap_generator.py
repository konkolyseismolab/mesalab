#mesalab/allplots/heatmap_generator.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import math
from matplotlib.colors import ListedColormap, BoundaryNorm

def generate_heatmaps_and_time_diff_csv(cross_data_df, summary_csv_path, unique_zs, unique_masses,
                                         plots_output_dir, analysis_results_output_dir,
                                         model_name="MESA Grid Analysis", # Kept for potential use in plot titles
                                         blue_loop_output_type='all', analyze_blue_loop=False):
    """
    Generates heatmaps from the cross-grid data (e.g., blue loop crossing counts)
    and calculates time differences based on the summary data.

    Args:
        cross_data_df (pd.DataFrame): DataFrame containing the grid data (Z as index, Mass as columns).
        summary_csv_path (str): Path to the summary CSV file generated by cli.py.
        unique_zs (list): Sorted list of unique Z values in the grid.
        unique_masses (list): Sorted list of unique mass values in the grid.
        plots_output_dir (str): Directory to save generated heatmaps.
        analysis_results_output_dir (str): Directory to save time difference CSV.
        model_name (str): Name of the MESA grid project for plot titles (e.g., from input_dir basename).
        blue_loop_output_type (str): 'summary' or 'all', affects what data is available.
        analyze_blue_loop (bool): True if blue loop analysis was performed.
    """

    if cross_data_df.empty:
        print("Warning: cross_data_df is empty. Cannot generate heatmaps.")
        return

    # Ensure index and columns are float for proper numerical operations and plotting
    cross_data_df.columns = pd.to_numeric(cross_data_df.columns, errors='coerce')
    cross_data_df.index = pd.to_numeric(cross_data_df.index, errors='coerce')

    # Drop any NaN columns/indices that might have resulted from conversion
    cross_data_df.dropna(axis=0, how='all', inplace=True)
    cross_data_df.dropna(axis=1, how='all', inplace=True)

    # Recalculate unique_zs_sorted and unique_masses_sorted from the potentially cleaned DataFrame
    unique_zs_sorted = sorted([z for z in cross_data_df.index.unique() if not pd.isna(z)])
    unique_masses_sorted = sorted([m for m in cross_data_df.columns.unique() if not pd.isna(m)])

    # Reindex the DataFrame to ensure it uses the sorted unique_zs and unique_masses
    cross_data_df_reindexed = cross_data_df.reindex(index=unique_zs_sorted, columns=unique_masses_sorted).astype(float)

    # Explicitly convert any remaining non-numeric/empty string values to NaN
    # This ensures that cmap.set_bad() correctly identifies and colors missing data.
    for col in cross_data_df_reindexed.columns:
        cross_data_df_reindexed[col] = pd.to_numeric(cross_data_df_reindexed[col], errors='coerce')

    print(f"DEBUG: cross_data_df_reindexed shape: {cross_data_df_reindexed.shape}")
    print(f"DEBUG: cross_data_df_reindexed has NaN values: {cross_data_df_reindexed.isnull().any().any()}")
    print(f"DEBUG: cross_data_df_reindexed head:\n{cross_data_df_reindexed.head()}")

    # --- Heatmap generation ---
    # Convert DataFrame to numpy array for imshow
    data_for_heatmap = cross_data_df_reindexed.to_numpy()

    # Define custom colors for the heatmap as requested:
    # 0 values are the darkest blue of viridis, NaN values are lightgrey, 1-5 use viridis.
    color_skipped = "lightgrey" # For NaN values (analysis skipped/error)

    # Get viridis colors for the actual crossing counts (0 to 5)
    # We get 6 distinct colors from the viridis colormap,
    # where the first color (index 0) will be the darkest blue for 0 crossings.
    viridis_full_range = plt.cm.viridis(np.linspace(0, 1, 6)) # 6 colors from dark to light viridis

    # Create the custom colormap using the viridis colors
    cmap = ListedColormap(viridis_full_range)

    # Set the color for bad (NaN) values to lightgrey
    cmap.set_bad(color=color_skipped) 

    # Set the color scale bounds for the custom colormap
    # -0.5 to 0.5 for 0, 0.5 to 1.5 for 1, etc.
    # This ensures that 0 maps to the first color, 1 to the second, etc.
    bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5]
    norm = BoundaryNorm(bounds, cmap.N)

    # Create the heatmap
    plt.figure(figsize=(20, 12))
    plt.imshow(data_for_heatmap, aspect='auto', origin='lower', cmap=cmap, norm=norm)

    # Colorbar settings - showing ticks for 0, 1, 2, 3, 4, 5
    cbar = plt.colorbar(ticks=[0, 1, 2, 3, 4, 5])
    cbar.set_label("Number of IS Crossings", fontsize=14)
    cbar.ax.set_yticklabels(["0", "1", "2", "3", "4", "5"])
    
    # Axis settings
    plt.xticks(np.arange(len(unique_masses_sorted)), [f'{m:.1f}' for m in unique_masses_sorted], rotation=90, fontsize=12)
    metallicity_tick_indices = np.arange(0, len(unique_zs_sorted), 5)
    plt.yticks(metallicity_tick_indices, [f'{unique_zs_sorted[i]:.4f}' for i in metallicity_tick_indices], fontsize=12)
    plt.xlabel("Mass [M$_\odot$]", fontsize=14)
    plt.ylabel("Metallicity (Z)", fontsize=14)
    plt.title(f"Heatmap: Mass vs. Metallicity ({model_name})", fontsize=16)

    # Use a generic filename for the heatmap now
    heatmap_filename = "mesa_grid_blue_loop_heatmap.png"
    plt.tight_layout()
    plt.savefig(os.path.join(plots_output_dir, heatmap_filename), dpi=300)
    plt.close()
    print(f"Generated heatmap: {heatmap_filename}")

    # Time differences logic (if analyze_blue_loop is True)
    if os.path.exists(summary_csv_path) and analyze_blue_loop:
        try:
            summary_df = pd.read_csv(summary_csv_path)

            # Ensure columns are numeric for calculation
            summary_df['blue_loop_start_age'] = pd.to_numeric(summary_df['blue_loop_start_age'], errors='coerce')
            summary_df['blue_loop_end_age'] = pd.to_numeric(summary_df['blue_loop_end_age'], errors='coerce')
            summary_df['instability_start_age'] = pd.to_numeric(summary_df['instability_start_age'], errors='coerce')
            summary_df['instability_end_age'] = pd.to_numeric(summary_df['instability_end_age'], errors='coerce')
            # Ensure crossing count is also numeric
            summary_df['blue_loop_crossing_count'] = pd.to_numeric(summary_df['blue_loop_crossing_count'], errors='coerce')


            # Round durations
            summary_df['calculated_blue_loop_duration'] = summary_df['calculated_blue_loop_duration'].apply(lambda x: round(x, 4) if pd.notna(x) else np.nan)
            summary_df['calculated_instability_duration'] = summary_df['calculated_instability_duration'].apply(lambda x: round(x, 4) if pd.notna(x) else np.nan)

            # --- Filtering Logic for Time Differences CSV ---
            # Only include rows where a valid blue loop was detected (crossing count > 0 and no NaNs in key ages)
            initial_rows = len(summary_df)
            filtered_df = summary_df[
                (summary_df['blue_loop_crossing_count'].notna()) &
                (summary_df['blue_loop_crossing_count'] > 0) &
                (summary_df['blue_loop_start_age'].notna()) &
                (summary_df['blue_loop_end_age'].notna())
            ].copy() # Use .copy() to avoid SettingWithCopyWarning

            if initial_rows > 0 and len(filtered_df) < initial_rows:
                print(f"Filtered out {initial_rows - len(filtered_df)} rows from time_differences CSV where no valid blue loop was detected.")
            # --- END Filtering Logic ---

            # Renamed output file for consistency
            time_diff_csv_path = os.path.join(analysis_results_output_dir, "mesa_grid_time_differences.csv")

            output_cols = [
                'initial_mass', 'initial_Z',
                'blue_loop_start_age', 'blue_loop_end_age', 'calculated_blue_loop_duration',
                'instability_start_age', 'instability_end_age', 'calculated_instability_duration'
            ]

            # Filter for columns that actually exist in the DataFrame before selecting
            # Use the filtered_df here!
            output_cols_existing = [col for col in output_cols if col in filtered_df.columns]

            if not output_cols_existing:
                print(f"Warning: No relevant time difference columns found in filtered data. Skipping generation of time differences CSV.")
            else:
                # Save the filtered DataFrame
                filtered_df[output_cols_existing].to_csv(time_diff_csv_path, index=False)
                print(f"Time differences CSV generated: {time_diff_csv_path}")

        except Exception as e:
            print(f"Error generating time differences CSV: {e}")
    else:
        print("Summary CSV not found or blue loop analysis not enabled. Skipping time differences CSV generation.")
